# Naive-Bayes-classifier
هدف این پروژه تشخیص موضوع خبر بین سیاسی و ورزشی است که برای پردازش زبان از کتابخانه هزم استفاده شده است و الگوریتم Naive Bayes  classifier پیاده سازی و استفاده شده است . همچنین به دلیل کوچک بودن احتمالات از روش لگاریتمی آن استفاده شده است. این پروژه قابلیت کرول کردن سایت های خبری را نیز دارا می باشد در نتیجه می توان این الگوریتم را روی این سایت ها نیز بررسی کرد<br />



# nlp_train.csv:
داده های train در آن قرار دارد.<br />


# clean_data.csv:
داده تمیز شده nlp_train.csv درآن ذخیره می شود.<br />


# final_data.csv:
پارامترهای train در این فایل ذخیره می شود.<br />



# alpha.txt: 
برای ذخیره سازی آلفا در فرمولNaive Bayes classifier که در هنگام TRAIN بدست می اورد.<br />

# Persian: 
در این فایل stopWord های زبان فارسی  قرار دارد که در بخش پردازش کمک می کند.<br />



# clean_test_data.csv:
داده تمیز شده در تابع pridict در آن ذخیره می شود.<br />


# model.py: 
پردازش زبان و پیش بینی نوع خبر در آن پیاده سازی شده است شامل چهار تابع است <br />
１-	make_parametr: <br /> 
برای تمیز کردن داده ها استفاده می شود <br />
２-	 make_final: <br />
برای train کردن مدل و بدست اوردن پارامتر ها استفاده می شود <br />
３-	Predict:<br />
با توجه به پارامتر ها یک فایل csv می گیرد و پیش بینی می کند به کدام دسته تعلق دارد اگه داده تمیز نباشد این تابع تابع make_parametr را نیز فراخوانی می کند. و در نهایت لیبل های پیش بینی شده را بر می گرداند. <br />
４-	f1: <br />
با تابع f1 نیز میزان دقت را اندازه گیری می کنیم که بالای ۹۹ درصد است. <br />



# crawler.ipynb and main_link.py:
کد کرول کردن سایت های خبری crawler.ipynb به کمک main_link.py مختلف را کرول می کند.

# tabnak.csv:
داده های کرول شده از سایت خبری تابناک
# varzesh3.csv:
داده های کرول شده سایت ورزش سه
# entekhab.csv: 
داده کرول شده سایت خبری انتخاب در آن ذخیره شده است.

# Entekhab2.csv:
داده های خالی که هنگام کرول بدست امده اند از entekhab.csv حذف می شوند


